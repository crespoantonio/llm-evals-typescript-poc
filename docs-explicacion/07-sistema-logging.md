# ğŸ“ Sistema de Logging - El Cronista del Framework

## Â¿QuÃ© es el Logger?

El **Logger** es como un **cronista medieval** que registra meticulosamente todo lo que pasa durante las evaluaciones. Imagina un escribano que anota:

- **ğŸ¬ CuÃ¡ndo empezÃ³ cada evaluaciÃ³n** â†’ Evento de inicio
- **â“ Cada pregunta que se hizo** â†’ Evento de sampling  
- **ğŸ“Š Cada calificaciÃ³n que se dio** â†’ Evento de mÃ©tricas
- **ğŸ CuÃ¡ndo y cÃ³mo terminÃ³** â†’ Evento final

**Â¿Por quÃ© es importante?**
- **ğŸ” Debugging** â†’ Si algo sale mal, puedes ver exactamente quÃ© pasÃ³
- **ğŸ“ˆ AnÃ¡lisis posterior** â†’ Estudiar patrones y tendencias
- **ğŸ”„ Reproducibilidad** â†’ Volver a analizar los mismos datos
- **ğŸ“Š AuditorÃ­a** â†’ Trazabilidad completa de cada evaluaciÃ³n

## ğŸ“š Tipos de Eventos que Registra

### 1. ğŸ¬ Evento 'spec' - EspecificaciÃ³n Inicial
```json
{
  "run_id": "20241231143045AB12CD",
  "event_id": 0,
  "type": "spec",
  "data": {
    "eval_name": "math-basic",
    "model": "gpt-4",
    "config": { /* configuraciÃ³n de la evaluaciÃ³n */ },
    "options": { /* opciones de ejecuciÃ³n */ },
    "started_at": "2024-12-31T14:30:45.123Z"
  },
  "created_at": "2024-12-31T14:30:45.123Z"
}
```

**Es como:** El cronista escribiendo "Hoy, 31 de diciembre, iniciamos la evaluaciÃ³n de matemÃ¡ticas bÃ¡sicas con GPT-4..."

### 2. ğŸ¤– Evento 'sampling' - Respuesta del Modelo
```json
{
  "run_id": "20241231143045AB12CD", 
  "event_id": 1,
  "sample_id": "sample_0",
  "type": "sampling",
  "data": {
    "input": [{"role": "user", "content": "Â¿CuÃ¡nto es 2+3?"}],
    "completion": "La respuesta es 5",
    "usage": {
      "prompt_tokens": 8,
      "completion_tokens": 4,
      "total_tokens": 12
    }
  },
  "created_at": "2024-12-31T14:30:47.456Z"
}
```

**Es como:** "El modelo respondiÃ³ '5' a la pregunta 'Â¿CuÃ¡nto es 2+3?', usando 12 tokens en total."

### 3. ğŸ“Š Evento 'metrics' - EvaluaciÃ³n de la Respuesta
```json
{
  "run_id": "20241231143045AB12CD",
  "event_id": 2, 
  "sample_id": "sample_0",
  "type": "metrics",
  "data": {
    "score": 1.0,
    "passed": true,
    "reasoning": "La respuesta '5' coincide exactamente con el ideal '5'"
  },
  "created_at": "2024-12-31T14:30:47.789Z"
}
```

**Es como:** "Calificamos la respuesta con 1.0 porque es perfectamente correcta."

### 4. ğŸ Evento 'final_report' - Resumen Final
```json
{
  "run_id": "20241231143045AB12CD",
  "event_id": 201,
  "type": "final_report", 
  "data": {
    "total_samples": 100,
    "correct": 87,
    "incorrect": 13,
    "score": 0.87
  },
  "created_at": "2024-12-31T14:35:23.456Z"
}
```

**Es como:** "Al final de la evaluaciÃ³n: 87 respuestas correctas de 100, puntuaciÃ³n final: 87%."

## ğŸ—ï¸ Arquitectura del Logger

```typescript
export class Logger {
  private events: Map<string, LogEvent[]> = new Map();
  //                   ^         ^
  //                run_id    eventos de esa ejecuciÃ³n
}
```

**Es como:** Un archivero donde cada cajÃ³n tiene una etiqueta (run_id) y contiene todos los documentos de esa evaluaciÃ³n especÃ­fica.

### Flujo de Trabajo:

```typescript
// 1. ğŸ“ Registrar evento
await logger.logEvent({
  run_id: 'ABC123',
  event_id: 1,
  type: 'sampling',
  data: { /* detalles */ }
});

// 2. ğŸ’¾ Guardar a archivo al final
await logger.saveToFile('mi-evaluacion.jsonl', 'ABC123');

// 3. ğŸ“– Cargar despuÃ©s para anÃ¡lisis
await logger.loadFromFile('mi-evaluacion.jsonl');

// 4. ğŸ“Š Obtener resumen
const resumen = logger.getSummary('ABC123');
```

## ğŸ“ Formato JSONL - LÃ­nea por LÃ­nea

Los logs se guardan en formato **JSONL** (JSON Lines):

```jsonl
{"run_id":"ABC123","event_id":0,"type":"spec","data":{...},"created_at":"2024-12-31T14:30:45.123Z"}
{"run_id":"ABC123","event_id":1,"type":"sampling","sample_id":"sample_0","data":{...},"created_at":"2024-12-31T14:30:47.456Z"}
{"run_id":"ABC123","event_id":2,"type":"metrics","sample_id":"sample_0","data":{...},"created_at":"2024-12-31T14:30:47.789Z"}
```

**Â¿Por quÃ© JSONL?**
- **ğŸ“ˆ Escalable** â†’ Puedes procesar archivos gigantes lÃ­nea por lÃ­nea
- **ğŸ”„ Streamable** â†’ Puedes leer mientras se estÃ¡ escribiendo
- **ğŸ› ï¸ EstÃ¡ndar** â†’ Compatible con herramientas de anÃ¡lisis de datos
- **ğŸ” FÃ¡cil de grep** â†’ `grep "sample_5" mi-log.jsonl`

## ğŸ› ï¸ Funcionalidades Principales

### 1. ğŸ“ Registro de Eventos
```typescript
async logEvent(event: LogEvent): Promise<void> {
  // Obtener lista de eventos para este run_id
  const runEvents = this.events.get(event.run_id) || [];
  
  // Agregar nuevo evento
  runEvents.push(event);
  
  // Guardar de vuelta en el Map
  this.events.set(event.run_id, runEvents);
}
```

**Es como:** Agregar una nueva pÃ¡gina al cuaderno de notas de una evaluaciÃ³n especÃ­fica.

### 2. ğŸ’¾ Guardar a Archivo
```typescript
async saveToFile(filePath: string, runId?: string): Promise<void> {
  // Crear directorio si no existe
  const dir = path.dirname(filePath);
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
  }

  // Obtener eventos a guardar
  let allEvents: LogEvent[] = [];
  if (runId) {
    allEvents = this.getEvents(runId);        // Solo una ejecuciÃ³n
  } else {
    for (const events of this.events.values()) {
      allEvents.push(...events);              // Todas las ejecuciones
    }
  }

  // Ordenar cronolÃ³gicamente
  allEvents.sort((a, b) => {
    if (a.run_id !== b.run_id) {
      return a.run_id.localeCompare(b.run_id);  // Por run_id primero
    }
    return a.event_id - b.event_id;             // Por event_id despuÃ©s
  });

  // Convertir a JSONL y guardar
  const jsonlContent = allEvents
    .map(event => JSON.stringify(event))
    .join('\n');
  
  fs.writeFileSync(filePath, jsonlContent);
}
```

### 3. ğŸ“– Cargar desde Archivo
```typescript
async loadFromFile(filePath: string): Promise<void> {
  const content = fs.readFileSync(filePath, 'utf-8');
  const lines = content.trim().split('\n');

  for (const line of lines) {
    if (!line.trim()) continue;  // Saltar lÃ­neas vacÃ­as
    
    try {
      const event = JSON.parse(line) as LogEvent;
      await this.logEvent(event);  // Restaurar en memoria
    } catch (error) {
      console.warn(`Failed to parse log line: ${line}`);
    }
  }
}
```

**Es como:** Leer un libro de crÃ³nicas y restaurar todos los eventos en tu memoria.

## ğŸ“Š AnÃ¡lisis de Logs

### 1. ğŸ“ˆ Resumen de EstadÃ­sticas
```typescript
getSummary(runId: string) {
  const events = this.getEvents(runId);
  
  // Buscar evento de reporte final (mÃ¡s preciso)
  const finalReportEvent = events.find(e => e.type === 'final_report');
  if (finalReportEvent) {
    return finalReportEvent.data;
  }
  
  // Si no hay reporte final, calcular desde eventos individuales
  const metricsEvents = events.filter(e => e.type === 'metrics');
  const total_samples = metricsEvents.length;
  const correct = metricsEvents.filter(e => e.data.passed === true).length;
  
  return {
    total_samples,
    correct,
    incorrect: total_samples - correct,
    score: total_samples > 0 ? correct / total_samples : 0
  };
}
```

### 2. ğŸ“ GeneraciÃ³n AutomÃ¡tica de Nombres
```typescript
static generateLogPath(runId: string, model: string, evalName: string): string {
  const timestamp = new Date().toISOString().slice(0, 10); // YYYY-MM-DD
  const logsDir = path.join(process.cwd(), 'logs');
  
  // Sanitizar nombres para Windows (reemplazar caracteres problemÃ¡ticos)
  const sanitizedModel = model.replace(/[:<>"|?*]/g, '-').replace(/\//g, '-');
  const sanitizedEval = evalName.replace(/[:<>"|?*]/g, '-');
  
  // Generar: logs/ABC123_gpt-4_math-basic.jsonl
  return path.join(logsDir, `${runId}_${sanitizedModel}_${sanitizedEval}.jsonl`);
}
```

**Resultado:** `logs/20241231143045AB12CD_gpt-4_math-basic.jsonl`

## ğŸ’¡ Casos de Uso PrÃ¡cticos

### ğŸ” Debugging - Encontrar el Problema

```typescript
import { Logger } from './logger';

async function debugearEvaluacion() {
  const logger = new Logger();
  
  // 1. Cargar logs de evaluaciÃ³n problemÃ¡tica
  await logger.loadFromFile('logs/evaluacion-fallida.jsonl');
  
  // 2. Obtener eventos de un run especÃ­fico
  const eventos = logger.getEvents('ABC123');
  
  // 3. Buscar errores o comportamientos extraÃ±os
  const errores = eventos.filter(e => 
    e.data.error || 
    (e.type === 'metrics' && e.data.passed === false)
  );
  
  console.log(`Encontrados ${errores.length} errores:`);
  errores.forEach(error => {
    console.log(`- Sample ${error.sample_id}: ${error.data.reasoning}`);
  });
  
  // 4. Analizar patrones de fallo
  const fallosSemanticos = eventos.filter(e => 
    e.type === 'metrics' && 
    e.data.reasoning?.includes('semantic')
  );
  
  console.log(`${fallosSemanticos.length} fallos semÃ¡nticos encontrados`);
}
```

### ğŸ“Š AnÃ¡lisis de Rendimiento

```typescript
async function analizarRendimiento() {
  const logger = new Logger();
  await logger.loadFromFile('logs/evaluacion-completa.jsonl');
  
  const eventos = logger.getEvents('ABC123');
  
  // Analizar tiempos entre eventos
  const samplingEvents = eventos.filter(e => e.type === 'sampling');
  const tiempos = [];
  
  for (let i = 1; i < samplingEvents.length; i++) {
    const anterior = new Date(samplingEvents[i-1].created_at).getTime();
    const actual = new Date(samplingEvents[i].created_at).getTime();
    tiempos.push(actual - anterior);
  }
  
  const tiempoPromedio = tiempos.reduce((a, b) => a + b, 0) / tiempos.length;
  
  console.log(`Tiempo promedio entre muestras: ${tiempoPromedio}ms`);
  
  // Analizar uso de tokens
  const tokensUsados = samplingEvents.map(e => e.data.usage?.total_tokens || 0);
  const tokensPromedio = tokensUsados.reduce((a, b) => a + b, 0) / tokensUsados.length;
  
  console.log(`Tokens promedio por muestra: ${tokensPromedio}`);
}
```

### ğŸ“ˆ ComparaciÃ³n HistÃ³rica

```typescript
async function compararEvaluaciones() {
  const logger1 = new Logger();
  const logger2 = new Logger();
  
  await logger1.loadFromFile('logs/evaluacion-version1.jsonl');
  await logger2.loadFromFile('logs/evaluacion-version2.jsonl');
  
  const resumen1 = logger1.getSummary('RUN1');
  const resumen2 = logger2.getSummary('RUN2');
  
  console.log('ComparaciÃ³n de versiones:');
  console.table([
    { 
      version: 'V1', 
      accuracy: (resumen1.score * 100).toFixed(2) + '%',
      samples: resumen1.total_samples
    },
    { 
      version: 'V2', 
      accuracy: (resumen2.score * 100).toFixed(2) + '%',
      samples: resumen2.total_samples
    }
  ]);
  
  const mejora = (resumen2.score - resumen1.score) * 100;
  console.log(`Mejora: ${mejora.toFixed(2)} puntos porcentuales`);
}
```

## ğŸ¯ Ejemplo de AnÃ¡lisis con Herramientas Externas

### ğŸ“Š Con jq (herramienta de lÃ­nea de comandos):

```bash
# Obtener todas las puntuaciones
jq -r 'select(.type == "metrics") | .data.score' evaluacion.jsonl

# Promedio de puntuaciÃ³n
jq -r 'select(.type == "metrics") | .data.score' evaluacion.jsonl | awk '{sum += $1; count++} END {print sum/count}'

# Contar fallos por tipo
jq -r 'select(.type == "metrics" and .data.passed == false) | .data.reasoning' evaluacion.jsonl | sort | uniq -c

# Uso de tokens por muestra
jq -r 'select(.type == "sampling") | .data.usage.total_tokens' evaluacion.jsonl
```

### ğŸ Con Python pandas:

```python
import pandas as pd
import json

# Cargar logs
logs = []
with open('evaluacion.jsonl', 'r') as f:
    for line in f:
        logs.append(json.loads(line))

df = pd.DataFrame(logs)

# AnÃ¡lisis de mÃ©tricas
metrics_df = df[df['type'] == 'metrics']
print(f"Accuracy promedio: {metrics_df['data'].apply(lambda x: x['score']).mean():.2%}")

# AnÃ¡lisis de tokens
sampling_df = df[df['type'] == 'sampling'] 
token_usage = sampling_df['data'].apply(lambda x: x.get('usage', {}).get('total_tokens', 0))
print(f"Tokens promedio: {token_usage.mean():.0f}")

# GrÃ¡fica de evoluciÃ³n de puntuaciones
import matplotlib.pyplot as plt
scores = metrics_df['data'].apply(lambda x: x['score'])
plt.plot(scores.values)
plt.title('EvoluciÃ³n de Puntuaciones')
plt.xlabel('Muestra')
plt.ylabel('Score')
plt.show()
```

## ğŸš¨ Mejores PrÃ¡cticas

### âœ… QuÃ© Hacer

1. **ğŸ“ Siempre especificar log_to_file** â†’ Para poder analizar despuÃ©s
2. **ğŸ·ï¸ Usar nombres descriptivos** â†’ Incluir fecha, modelo, evaluaciÃ³n
3. **ğŸ’¾ Guardar logs en control de versiones** â†’ Para comparaciones histÃ³ricas
4. **ğŸ“Š Analizar logs periÃ³dicamente** â†’ Detectar patrones y problemas
5. **ğŸ§¹ Limpiar logs antiguos** â†’ Evitar que crezcan indefinidamente

### âŒ QuÃ© Evitar

1. **ğŸš« No guardar informaciÃ³n sensible** â†’ API keys, datos personales
2. **ğŸš« No ignorar errores de parsing** â†’ Pueden indicar problemas
3. **ğŸš« No acumular logs gigantes** â†’ Implementar rotaciÃ³n
4. **ğŸš« No usar en cÃ³digo crÃ­tico sin try/catch** â†’ El logging no debe romper la evaluaciÃ³n

## ğŸ“ Puntos Clave para Recordar

1. **El Logger es tu caja negra** â†’ Registra todo para anÃ¡lisis posterior
2. **JSONL permite anÃ¡lisis escalable** â†’ Una lÃ­nea = un evento
3. **Los run_id agrupan eventos** â†’ Cada evaluaciÃ³n tiene su cronologÃ­a
4. **Los event_id mantienen orden** â†’ Secuencia cronolÃ³gica dentro de cada run
5. **Los logs son para debugging Y anÃ¡lisis** â†’ No solo cuando hay problemas
6. **La estructura consistente facilita herramientas** â†’ jq, pandas, etc.

**Â¡Siguiente paso:** Vamos a ver la interfaz de lÃ­nea de comandos que une todo! ğŸ–¥ï¸
