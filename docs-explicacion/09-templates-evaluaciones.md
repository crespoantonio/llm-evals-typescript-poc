# ğŸ§ª Templates de Evaluaciones - Los Tipos de ExÃ¡menes

## Â¿QuÃ© son los Templates de EvaluaciÃ³n?

Los **templates de evaluaciÃ³n** son como **diferentes tipos de exÃ¡menes** que un profesor puede usar en su clase:

- **ğŸ“ Examen de respuesta Ãºnica** â†’ Solo hay una respuesta correcta (2+2=4)
- **ğŸ‘©â€ğŸ« Examen corregido por profesor** â†’ Un experto evalÃºa la calidad 
- **â˜‘ï¸ Examen de opciÃ³n mÃºltiple** â†’ Eliges entre opciones predefinidas
- **ğŸ§  Examen de comprensiÃ³n** â†’ El significado importa mÃ¡s que las palabras exactas

Cada template **sabe cÃ³mo evaluar** un tipo especÃ­fico de respuesta y **dar una calificaciÃ³n justa**.

## ğŸ¯ Los 4 Tipos de Templates

### 1. ğŸ¯ BasicEval - El Examinador Estricto

**Â¿CuÃ¡ndo usar?**
- âœ… Preguntas con respuestas exactas y objetivas
- âœ… MatemÃ¡ticas, fechas, nombres especÃ­ficos
- âœ… Cuando necesitas precisiÃ³n absoluta

**Ejemplo de uso:**
```yaml
evaluacion-matematicas:
  id: math.v1
  description: "EvaluaciÃ³n de matemÃ¡ticas bÃ¡sicas"
  class: BasicEval
  args:
    samples_jsonl: math/basicas.jsonl
    match_type: exact      # exact, includes, fuzzy, regex
    case_sensitive: false  # true/false
```

#### ğŸ”§ Tipos de ComparaciÃ³n

**`exact`** - Matching Exacto
```
Pregunta: "Â¿CuÃ¡nto es 2+2?"
Ideal: "4"
âœ… Respuesta: "4" â†’ APRUEBA
âŒ Respuesta: "cuatro" â†’ FALLA
âŒ Respuesta: "La respuesta es 4" â†’ FALLA
```

**`includes`** - Contiene la Respuesta
```
Pregunta: "Â¿CuÃ¡l es la capital de Francia?"  
Ideal: "ParÃ­s"
âœ… Respuesta: "La capital es ParÃ­s" â†’ APRUEBA
âœ… Respuesta: "ParÃ­s es la capital" â†’ APRUEBA
âŒ Respuesta: "Es una ciudad francesa" â†’ FALLA
```

**`fuzzy`** - Matching Aproximado (para typos)
```
Pregunta: "Â¿CÃ³mo se llama el autor de Don Quijote?"
Ideal: "Cervantes"
âœ… Respuesta: "Cervantes" â†’ APRUEBA
âœ… Respuesta: "Servantes" â†’ APRUEBA (typo menor)
âœ… Respuesta: "Miguel de Cervantes" â†’ APRUEBA
âŒ Respuesta: "Shakespeare" â†’ FALLA
```

**`regex`** - PatrÃ³n Regular
```yaml
# Para validar formatos especÃ­ficos
match_type: regex
ideal: "\\d{4}-\\d{2}-\\d{2}"  # Formato fecha YYYY-MM-DD

âœ… Respuesta: "2024-12-31" â†’ APRUEBA
âŒ Respuesta: "31/12/2024" â†’ FALLA
```

#### ğŸ’¡ Ejemplo PrÃ¡ctico Completo

```jsonl
{"input": [{"role": "user", "content": "Â¿CuÃ¡nto es 15 + 27?"}], "ideal": "42"}
{"input": [{"role": "user", "content": "Â¿En quÃ© aÃ±o llegÃ³ ColÃ³n a AmÃ©rica?"}], "ideal": ["1492", "En 1492"]}
{"input": [{"role": "user", "content": "Â¿CÃ³mo se dice 'hello' en francÃ©s?"}], "ideal": "bonjour"}
```

**Dataset para mÃºltiples respuestas vÃ¡lidas:**
```jsonl
{"input": [{"role": "user", "content": "Â¿CuÃ¡l es la capital de EspaÃ±a?"}], "ideal": ["Madrid", "madrid", "La capital es Madrid"]}
```

### 2. ğŸ‘©â€ğŸ« ModelGradedEval - El Profesor de IA

**Â¿CuÃ¡ndo usar?**
- âœ… Respuestas abiertas que requieren comprensiÃ³n
- âœ… Ensayos, explicaciones, anÃ¡lisis
- âœ… Cuando hay mÃºltiples formas correctas de responder
- âœ… Evaluaciones cualitativas

**Ejemplo de configuraciÃ³n:**
```yaml
ensayos-historia:
  id: history-essays.v1
  description: "EvaluaciÃ³n de ensayos histÃ³ricos por IA"
  class: ModelGradedEval
  args:
    samples_jsonl: historia/ensayos.jsonl
    eval_type: cot_classify           # classify o cot_classify
    grading_model: gpt-4             # Modelo que califica
    grading_prompt: |
      Eres un profesor de historia evaluando ensayos.
      
      PREGUNTA: {input}
      RESPUESTA DEL ESTUDIANTE: {completion}
      RESPUESTA IDEAL: {ideal}
      
      EvalÃºa la respuesta considerando:
      1. PrecisiÃ³n histÃ³rica
      2. ComprensiÃ³n del tema
      3. Calidad de la argumentaciÃ³n
      
      Responde SOLO con:
      CORRECT - Si la respuesta es correcta y completa
      INCORRECT - Si la respuesta es incorrecta o incompleta
```

#### ğŸ§  Tipos de EvaluaciÃ³n

**`classify`** - ClasificaciÃ³n Simple
- El modelo califica directamente: CORRECT/INCORRECT
- MÃ¡s rÃ¡pido y barato
- Bueno para evaluaciones claras

**`cot_classify`** - Chain of Thought (Razonamiento Paso a Paso)
- El modelo explica su razonamiento primero
- DespuÃ©s da la calificaciÃ³n
- MÃ¡s preciso pero mÃ¡s caro
- Mejor para evaluaciones complejas

#### ğŸ’¡ Ejemplo de Dataset

```jsonl
{"input": [{"role": "user", "content": "Explica las causas principales de la Primera Guerra Mundial"}], "ideal": "Las principales causas fueron el imperialismo, el sistema de alianzas, el nacionalismo y el asesinato del archiduque Francisco Fernando"}

{"input": [{"role": "user", "content": "Â¿Por quÃ© fue importante la RevoluciÃ³n Industrial?"}], "ideal": "TransformÃ³ la economÃ­a, la sociedad y la tecnologÃ­a, cambiando de una economÃ­a agrÃ­cola a una industrial"}
```

### 3. â˜‘ï¸ ChoiceBasedEval - El Examen Personalizado

**Â¿CuÃ¡ndo usar?**
- âœ… Cuando quieres control granular sobre la calificaciÃ³n
- âœ… Evaluaciones con criterios mÃºltiples
- âœ… Calificaciones no binarias (parcialmente correcto)
- âœ… Rubrics complejas de evaluaciÃ³n

**Ejemplo de configuraciÃ³n:**
```yaml
escritura-creativa:
  id: creative-writing.v1
  description: "EvaluaciÃ³n de escritura creativa con criterios mÃºltiples"
  class: ChoiceBasedEval
  args:
    samples_jsonl: escritura/cuentos.jsonl
    grading_model: gpt-4
    prompt: |
      EvalÃºa este cuento considerando creatividad, gramÃ¡tica y estructura:
      
      CUENTO: {completion}
      CRITERIOS IDEALES: {ideal}
      
      Â¿CÃ³mo calificarÃ­as este cuento?
    choice_strings: 
      - "EXCELENTE"
      - "BUENO" 
      - "REGULAR"
      - "NECESITA_MEJORA"
    choice_scores:
      EXCELENTE: 1.0
      BUENO: 0.75
      REGULAR: 0.5
      NECESITA_MEJORA: 0.25
```

#### ğŸ¯ Sistema de PuntuaciÃ³n Flexible

```yaml
# EvaluaciÃ³n de traducciÃ³n con matices
choice_strings: ["PERFECTO", "CASI_PERFECTO", "CORRECTO", "PARCIAL", "INCORRECTO"]
choice_scores:
  PERFECTO: 1.0        # TraducciÃ³n perfecta
  CASI_PERFECTO: 0.9   # PequeÃ±os detalles menores
  CORRECTO: 0.7        # Correcto pero no idiomÃ¡tico
  PARCIAL: 0.4         # Algunas partes correctas
  INCORRECTO: 0.0      # Completamente incorrecto
```

#### ğŸ’¡ Ejemplo de Dataset

```jsonl
{"input": [{"role": "user", "content": "Escribe un cuento corto sobre la luna"}], "ideal": "Debe incluir elementos creativos, buena gramÃ¡tica, estructura narrativa clara con inicio, desarrollo y final"}

{"input": [{"role": "user", "content": "Traduce: 'The weather is beautiful today'"}], "ideal": "El clima estÃ¡ hermoso hoy / El tiempo estÃ¡ precioso hoy / Hace un dÃ­a hermoso"}
```

### 4. ğŸ§  SemanticSimilarityEval - El Entendedor de Significados

**Â¿CuÃ¡ndo usar?**
- âœ… Respuestas conceptuales donde las palabras exactas no importan
- âœ… SinÃ³nimos y parÃ¡frasis son vÃ¡lidos
- âœ… Evaluaciones de comprensiÃ³n de lectura
- âœ… Cuando el significado es mÃ¡s importante que la forma

**Ejemplo de configuraciÃ³n:**
```yaml
comprension-lectora:
  id: reading-comprehension.v1
  description: "EvaluaciÃ³n por similitud semÃ¡ntica"
  class: SemanticSimilarityEval
  args:
    samples_jsonl: lectura/comprension.jsonl
    threshold: 0.85                    # MÃ­nima similitud para aprobar (0-1)
    embeddings_provider: openai        # openai o local
    embeddings_model: text-embedding-3-small
    match_mode: best                   # best, threshold, all
    cache_embeddings: true            # Cachear para ahorro
```

#### ğŸšï¸ ParÃ¡metros Importantes

**`threshold`** - Umbral de Similitud
```yaml
threshold: 0.9   # Muy estricto (90% similitud)
threshold: 0.8   # Estricto (80% similitud)  
threshold: 0.7   # Moderado (70% similitud)
threshold: 0.6   # Relajado (60% similitud)
```

**`match_mode`** - Modo de ComparaciÃ³n
```yaml
match_mode: best      # Usa la mejor puntuaciÃ³n entre mÃºltiples ideales
match_mode: threshold # Todas deben superar el threshold
match_mode: all      # Promedio de todas las comparaciones
```

**`embeddings_provider`** - Proveedor de Embeddings
```yaml
embeddings_provider: openai  # MÃ¡s preciso, cuesta dinero
embeddings_provider: local   # Gratis, menos preciso
```

#### ğŸ’¡ Ejemplo PrÃ¡ctico

```jsonl
{"input": [{"role": "user", "content": "Â¿QuÃ© significa la expresiÃ³n 'llover a cÃ¡ntaros'?"}], "ideal": ["Llueve mucho", "Llueve intensamente", "Lluvia muy fuerte"]}

{"input": [{"role": "user", "content": "Resume el concepto de fotosÃ­ntesis"}], "ideal": "Proceso por el cual las plantas convierten luz solar en energÃ­a usando diÃ³xido de carbono y agua"}
```

**Respuestas que aprobarÃ­an:**
- "Las plantas usan la luz del sol para crear energÃ­a" âœ… (similitud: ~0.82)
- "ConversiÃ³n de CO2 y H2O en glucosa mediante energÃ­a solar" âœ… (similitud: ~0.89)
- "Proceso que hacen las hojas para alimentarse con sol" âœ… (similitud: ~0.76)

## ğŸ”„ ComparaciÃ³n de Templates

| Template | PrecisiÃ³n | Flexibilidad | Costo | Velocidad | Mejor para |
|----------|-----------|--------------|-------|-----------|------------|
| **BasicEval** | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ | â­ | ğŸ’° | âš¡âš¡âš¡ | Respuestas exactas |
| **ModelGraded** | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’° | âš¡ | Evaluaciones complejas |
| **ChoiceBased** | ğŸ¯ğŸ¯ğŸ¯ğŸ¯ | â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’° | âš¡ | Control granular |
| **Semantic** | ğŸ¯ğŸ¯ğŸ¯ | â­â­â­ | ğŸ’°ğŸ’° | âš¡âš¡ | Significado conceptual |

## ğŸ› ï¸ Combinando Templates - Estrategias Avanzadas

### Estrategia 1: Pipeline de EvaluaciÃ³n
```yaml
# Primer filtro: BasicEval para respuestas obvias
matematicas-nivel1:
  class: BasicEval
  args:
    match_type: exact

# Segundo filtro: SemanticSimilarity para casos complejos  
matematicas-nivel2:
  class: SemanticSimilarityEval
  args:
    threshold: 0.8
```

### Estrategia 2: EvaluaciÃ³n por Dominio
```yaml
# Para cÃ³digo: BasicEval (sintaxis exacta)
codigo-sintaxis:
  class: BasicEval
  args:
    case_sensitive: true
    match_type: fuzzy

# Para explicaciones de cÃ³digo: ModelGraded
codigo-explicacion:
  class: ModelGradedEval
  args:
    grading_model: gpt-4
```

### Estrategia 3: EvaluaciÃ³n Multinivel
```yaml
# Nivel bÃ¡sico: Â¿Es correcto?
nivel-basico:
  class: BasicEval
  
# Nivel avanzado: Â¿QuÃ© tan completo?
nivel-avanzado:
  class: ChoiceBasedEval
  choice_scores:
    COMPLETO: 1.0
    PARCIAL: 0.6
    BASICO: 0.3
```

## ğŸ’¡ Casos de Uso Reales

### ğŸ“š EvaluaciÃ³n Educativa
```yaml
# MatemÃ¡ticas elementales
math-elementary:
  class: BasicEval
  args:
    match_type: exact

# ComprensiÃ³n de lectura  
reading-comprehension:
  class: SemanticSimilarityEval
  args:
    threshold: 0.75

# Ensayos de literatura
literature-essays:
  class: ModelGradedEval
  args:
    eval_type: cot_classify
    grading_model: gpt-4
```

### ğŸ’» EvaluaciÃ³n TÃ©cnica
```yaml
# Sintaxis de programaciÃ³n
code-syntax:
  class: BasicEval
  args:
    case_sensitive: true
    match_type: fuzzy

# Explicaciones tÃ©cnicas
code-explanation:
  class: SemanticSimilarityEval
  args:
    threshold: 0.8

# RevisiÃ³n de cÃ³digo
code-review:
  class: ChoiceBasedEval
  choice_strings: ["EXCELENTE", "BUENO", "NECESITA_MEJORA", "REFACTORIZAR"]
  choice_scores: {EXCELENTE: 1.0, BUENO: 0.75, NECESITA_MEJORA: 0.5, REFACTORIZAR: 0.2}
```

### ğŸŒ EvaluaciÃ³n de Idiomas
```yaml
# Vocabulario (respuesta exacta)
vocabulary:
  class: BasicEval
  args:
    match_type: includes
    case_sensitive: false

# ConversaciÃ³n (comprensiÃ³n)
conversation:
  class: SemanticSimilarityEval
  args:
    threshold: 0.7

# ComposiciÃ³n (calidad)
composition:
  class: ModelGradedEval
  args:
    grading_model: gpt-4
    eval_type: cot_classify
```

## ğŸš¨ Errores Comunes y CÃ³mo Evitarlos

### âŒ BasicEval demasiado estricto
```yaml
# Problema: No reconoce respuestas vÃ¡lidas
match_type: exact
ideal: "4"

# Usuario responde: "La respuesta es 4" â†’ FALLA

# âœ… SoluciÃ³n: Usar includes o mÃºltiples ideales
match_type: includes
ideal: ["4", "cuatro", "La respuesta es 4"]
```

### âŒ SemanticSimilarity threshold mal configurado
```yaml
# Problema: Threshold muy alto rechaza respuestas vÃ¡lidas
threshold: 0.95  # Demasiado estricto

# âœ… SoluciÃ³n: Probar diferentes valores
threshold: 0.8   # MÃ¡s realista
```

### âŒ ModelGraded sin prompt especÃ­fico
```yaml
# Problema: Prompt genÃ©rico da resultados inconsistentes
grading_prompt: "Â¿EstÃ¡ correcto?"

# âœ… SoluciÃ³n: Prompt especÃ­fico con criterios claros
grading_prompt: |
  EvalÃºa si la respuesta matemÃ¡tica es correcta.
  Criterios: mÃ©todo correcto, cÃ¡lculos precisos, respuesta final correcta.
  Responde CORRECT solo si cumple todos los criterios.
```

## ğŸ“ Puntos Clave para Recordar

1. **Cada template tiene su propÃ³sito especÃ­fico** â†’ Elige el correcto para tu caso
2. **BasicEval para precisiÃ³n, otros para flexibilidad** â†’ Balance entre exactitud y comprensiÃ³n
3. **Los prompts de grading son crÃ­ticos** â†’ Invierte tiempo en hacerlos bien
4. **Los thresholds necesitan ajuste** â†’ Experimenta para encontrar el balance
5. **Los datasets deben coincidir con el template** â†’ Prepara datos apropiados
6. **La combinaciÃ³n de templates es poderosa** â†’ Una evaluaciÃ³n puede usar varios
7. **El costo aumenta con la complejidad** â†’ BasicEval es gratis, ModelGraded cuesta

### ğŸ¯ GuÃ­a de SelecciÃ³n RÃ¡pida

**Â¿Hay una respuesta Ãºnica y objetiva?** â†’ **BasicEval**
**Â¿Necesitas evaluar comprensiÃ³n o creatividad?** â†’ **ModelGradedEval**  
**Â¿Quieres control granular de puntuaciones?** â†’ **ChoiceBasedEval**
**Â¿El significado importa mÃ¡s que las palabras exactas?** â†’ **SemanticSimilarityEval**

**Â¡Siguiente paso:** Vamos a ver cÃ³mo funciona el sistema de cachÃ© que ahorra dinero! âš¡
